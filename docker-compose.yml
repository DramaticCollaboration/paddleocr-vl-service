version: '3.8'

services:
  paddleocr-vl:
    build:
      context: .
      dockerfile: Dockerfile
    image: paddleocr-vl-service:latest
    container_name: paddleocr-vl-service

    # GPU configuration
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

    # Environment variables
    environment:
      - APP_NAME=PaddleOCR-VL Service
      - APP_VERSION=1.0.0
      - APP_PORT=8000
      - APP_HOST=0.0.0.0
      - DEBUG=false
      - LOG_LEVEL=INFO
      - LOG_FORMAT=json
      - USE_GPU=true
      - DEVICE=gpu
      - MAX_UPLOAD_SIZE=52428800  # 50MB
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility

    # Ports
    ports:
      - "8070:8000"

    # Volumes for temporary files only (models now pre-packaged in image)
    volumes:
      - /tmp/paddleocr:/tmp/paddleocr

    # Restart policy
    restart: unless-stopped

    # Health check
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s

    # Logging
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"
    networks:
      - proxy
    labels:
      - "traefik.enable=true"
      - "traefik.http.routers.paddleocr.rule=Host(`paddleocr.empasy.com`)"
      - "traefik.http.routers.paddleocr.entrypoints=websecure"
      - "traefik.http.routers.paddleocr.tls=true"
      - "traefik.http.routers.paddleocr.tls.certresolver=myresolver"
      - "traefik.http.routers.paddleocr.service=paddleocr"
      - "traefik.http.services.paddleocr.loadbalancer.server.port=8000"
      - "traefik.http.services.paddleocr.loadbalancer.server.scheme=http"

networks:
  proxy:
    external: true # Or define it here if not already existing